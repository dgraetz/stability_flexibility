---
title: "AlternateRunsAnalysis"
author: "Sophia Angleton"
format: html
editor: visual
---

## Multilevel Test of Stability-Flexibility

This script cleans and analyses the AlternateRuns Dataset.

**Variables** - block: 0 for practice, there are a total of 8 blocks per part and each block consists of 112 trials. So 896 trials per participant over all 7 blocks (not counting practice)

-   bal: counterbalancing of conditions across blocks

-   x, y, c2: irrelevant (already taken out)

-   cycle: counting within full alternating cycle (8), switch at 1 and 5

-   task: 1=shape, 2=color

-   dimshape=specific shapes--4=neutral

-   dimcolor=specific color--4=neutral

-   correct: correct response (i.e., value of the currently relevant task dimension)

-   error: 0 = no error, 1 = yes error

-   response: actual response

-   RT: or response time

```{r}
#| include: false
library(tidyverse)
library(janitor)
library(readr)
library(rio)
library(psych) 
library(lme4)
library(sjPlot)
#import dataset
AlternateRuns <- read_csv("AlternateRuns.csv")
#view(AlternateRuns)
```

## Data Cleaning

Rename variables for clarity, remove practice blocks and subjects with \> 80% accuracy, compute z-scores and create switch + valence + lag variables.

```{r}
#rename columns to understand better
alt_run <- AlternateRuns %>% 
  rename(dimshape = dim1, dimcolor = dim2, rt = time) %>% #remane variables
  filter(block != 0) #filter practice trials out

#determine 80% accuracy 
crit <- 896 - (896 * .8)
#crit # need at least 179 out of 896 trials to be correct, denoted by 0 in error col
sum_er <- alt_run %>% 
  group_by(id) %>% 
summarize(sum = sum(error))

sum_er <- sum_er %>% 
  mutate(outlier_er =  (sum > crit)) %>% 
  filter(outlier_er == !FALSE) #two people fall below 80% accuracy

alt_run <- alt_run %>% 
  filter(id != 70, id != 87) #removing those outliers here 

#Making new variables
alt_run <- alt_run %>% 
  group_by(id, block) %>%
  mutate(
    switch = if_else(cycle %in% c(1,5), 1, 0),
    cycle2 = ifelse(cycle > 4, cycle - 4, cycle), # i didnt want to overwrite cycle, but this is breaking the cycle of 8 into 1-4 
    group = ifelse(cycle2 == 1,1,0),
    lerror = lag(error, 1), 
    ltrial = lag(trial, 1), 
    lrt = lag(rt, 1),
    valence = if_else(dimshape == 4 | dimcolor == 4,1,2),#univalent = 1, bivalalent = 2
    lvalence = lag(valence, 4))#lvalence l = 1 group so for me 4 ... is this right? 

alt_run <- alt_run %>% #making contrasts outlined in prereg
  group_by(id, block, group) %>% 
  mutate(
    lvalence_contr = case_when(lvalence == 1 ~ -0.5, lvalence == 2 ~ 0.5),
    valence_contr = case_when(valence == 1 ~ -0.5, valence == 2 ~ 0.5)
    )

#compute z-score on trial level 
alt_run_z <- alt_run %>% 
  group_by(id, cycle2, valence, lvalence) %>% #cycle or cycle2
  mutate(
    z = (rt - mean(rt[error == 0 & lerror == 0])) / sd(rt[error == 0 & lerror == 0])) %>% 
  ungroup()

# Overall count 
overall_outliers <- alt_run_z %>% summarize(n_outliers = sum(abs(z) > 3, na.rm = TRUE)) #overall_outliers

# Per participant 
outliers_by_id <- alt_run_z %>% 
  group_by(id) %>%
  summarize(n_outliers = sum(abs(z) > 3, na.rm = TRUE))
#outliers_by_id

#Remove zâ€‘score outliers
alt_run <- alt_run_z %>%
  filter(abs(z) <= 3 | is.na(z)) 


# Final summary dataset
z_score_inspect <- alt_run %>%
  group_by(id, cycle2, valence, lvalence) %>%
  summarize( 
    z_score_mean = mean(z, na.rm = TRUE), 
    z_score_sd = sd(z, na.rm = TRUE), 
    response_time_mean = mean(rt, na.rm = TRUE),
    response_time_sd = sd(rt, na.rm = TRUE) 
    )
z_score_inspect

#I think somewhere in here I need to filter out first trials but I dont know where I should put this in my workflow
```



**Analysis On The Experimental Level:** Here we test whether experimental manipulations of previous and current trial control demands interact with the switch contrast in a manner that is consistent with a flexibility/stability tradeoff model. 


```{r}

model_lmer <- lmer(
  rt ~ valence * lvalence * switch +
    (valence + lvalence + switch | id),
  data = alt_run
)

summary(model_lmer)

tab_model(model_lmer, show.est = T, auto.label = F, show.stat = T)
```
```{r}
model_glmer <- glmer(
  error ~ valence * lvalence*switch + (valence + lvalence + switch|id), family = 'binomial', control = glmerControl(optimizer = 'bobyqa'), data = alt_run
)

summary(model_glmer)

tab_model(model_glmer, show.est = T, auto.label = F, show.stat = T)
```

